# Explorando Capas Convolucionales a Trav√©s de Datos y Experimentos

**Autor**: Deisy Lorena Guzm√°n Cabrales 

---

## üìã Tabla de Contenidos
- [Descripci√≥n del Problema](#descripci√≥n-del-problema)
- [Descripci√≥n del Dataset](#descripci√≥n-del-dataset)
- [Dise√±o de Arquitectura](#dise√±o-de-arquitectura)
- [Resultados Experimentales](#resultados-experimentales)
- [Interpretaci√≥n y Conocimientos Clave](#interpretaci√≥n-y-conocimientos-clave)
- [Estructura del Repositorio](#estructura-del-repositorio)
- [Configuraci√≥n y Requisitos](#configuraci√≥n-y-requisitos)
- [C√≥mo Ejecutar](#c√≥mo-ejecutar)
- [Despliegue del Modelo](#despliegue-del-modelo)
- [Referencias](#referencias)

---

## üéØ Descripci√≥n del Problema

Este proyecto explora las **redes neuronales convolucionales (CNNs)** no como modelos de caja negra, sino como componentes arquitect√≥nicos cuyas decisiones de dise√±o afectan directamente el rendimiento, escalabilidad e interpretabilidad.

### Objetivos de Aprendizaje

1. Comprender la intuici√≥n matem√°tica detr√°s de las capas convolucionales
2. Analizar c√≥mo las decisiones arquitect√≥nicas (tama√±o de kernel, profundidad, stride, padding) afectan el aprendizaje
3. Comparar capas convolucionales con capas totalmente conectadas para datos tipo imagen
4. Realizar an√°lisis exploratorio de datos (EDA) significativo para tareas de redes neuronales
5. Comunicar decisiones arquitect√≥nicas y experimentales de manera clara

### Enfoque

En lugar de seguir una receta, este proyecto:
- **Selecciona** un dataset apropiado con justificaci√≥n
- **Analiza** caracter√≠sticas del dataset a trav√©s de EDA
- **Dise√±a** arquitecturas CNN desde cero con razonamiento expl√≠cito
- **Conduce** experimentos controlados sobre par√°metros arquitect√≥nicos
- **Interpreta** resultados a trav√©s del lente del sesgo inductivo
- **Despliega** el modelo para inferencia en producci√≥n

---

## üìä Descripci√≥n del Dataset

### Fashion-MNIST

**Fuente**: [TensorFlow Keras Datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist)  
**Repositorio Original**: https://github.com/zalandoresearch/fashion-mnist

### Caracter√≠sticas del Dataset

- **Tarea**: Clasificaci√≥n de im√°genes multi-clase
- **Clases**: 10 categor√≠as de moda
  - 0: Camiseta/top
  - 1: Pantal√≥n
  - 2: Su√©ter
  - 3: Vestido
  - 4: Abrigo
  - 5: Sandalia
  - 6: Camisa
  - 7: Zapatilla deportiva
  - 8: Bolso
  - 9: Bot√≠n

- **Tama√±o**: 
  - Conjunto de entrenamiento: 60,000 im√°genes
  - Conjunto de prueba: 10,000 im√°genes
- **Dimensiones de imagen**: 28√ó28 p√≠xeles
- **Canales**: 1 (escala de grises)
- **Rango de p√≠xeles**: [0, 255]
- **Balance de clases**: Perfectamente balanceado (6,000 muestras por clase en entrenamiento)

### ¬øPor Qu√© Fashion-MNIST?

Fashion-MNIST es ideal para estudiar capas convolucionales porque:

1. **Estructura Espacial**: Las prendas de moda contienen patrones locales (texturas, bordes) que se benefician de la conectividad local
2. **Invariancia por Traslaci√≥n**: Los objetos permanecen reconocibles independientemente de su posici√≥n ‚Äì exactamente lo que proporciona la convoluci√≥n
3. **Caracter√≠sticas Jer√°rquicas**: Las capas inferiores detectan bordes/texturas, las capas m√°s profundas detectan partes de objetos (mangas, tacones)
4. **Desafiante pero Manejable**: M√°s dif√≠cil que los d√≠gitos MNIST, haciendo visibles las diferencias arquitect√≥nicas
5. **Tama√±o Pr√°ctico**: Cabe en memoria y entrena r√°pidamente para experimentaci√≥n r√°pida

---

## üèóÔ∏è Dise√±o de Arquitectura

### Modelo Base (No Convolucional)

**Prop√≥sito**: Establecer referencia de rendimiento sin sesgo inductivo espacial

```
Input (784) 
    ‚Üì
Dense(128, ReLU) + Dropout(0.2)
    ‚Üì
Dense(64, ReLU) + Dropout(0.2)
    ‚Üì
Dense(10, Softmax)
```

**Par√°metros**: ~101,000  
**Limitaci√≥n Clave**: Trata los p√≠xeles como caracter√≠sticas independientes, ignorando la estructura espacial

---

### Modelo CNN (Convolucional)

**Arquitectura Propuesta**:

```
Input (28√ó28√ó1)
    ‚Üì
Conv2D(32 filtros, 3√ó3, ReLU) + BatchNorm
    ‚Üì
Conv2D(32 filtros, 3√ó3, ReLU) + BatchNorm
    ‚Üì
MaxPooling(2√ó2)
    ‚Üì
Conv2D(64 filtros, 3√ó3, ReLU) + BatchNorm
    ‚Üì
Conv2D(64 filtros, 3√ó3, ReLU) + BatchNorm
    ‚Üì
MaxPooling(2√ó2)
    ‚Üì
Flatten
    ‚Üì
Dense(128, ReLU) + Dropout(0.3)
    ‚Üì
Dense(10, Softmax)
```

**Par√°metros**: ~94,000  
**Ventaja**: Menos par√°metros que el modelo base, mejor rendimiento

---

### Justificaciones Arquitect√≥nicas

#### ¬øPor Qu√© Kernels 3√ó3?
- **Eficiente**: Dos capas 3√ó3 = mismo campo receptivo que 5√ó5, pero menos par√°metros
- **M√°s no-linealidad**: Apilar capas peque√±as agrega funciones de activaci√≥n
- **Est√°ndar de la industria**: Usado en VGG, ResNet y arquitecturas modernas

#### ¬øPor Qu√© Dos Capas Conv Antes del Pooling?
- **Caracter√≠sticas jer√°rquicas**: La primera capa encuentra bordes, la segunda los combina
- **Preserva resoluci√≥n**: No reduce el muestreo demasiado pronto
- **Agrega profundidad**: M√°s poder representacional

#### ¬øPor Qu√© MaxPooling 2√ó2?
- **Reduce gradualmente**: Dimensiones espaciales 28‚Üí14‚Üí7
- **Invariancia por traslaci√≥n**: Peque√±os desplazamientos no afectan la salida
- **Reduce par√°metros**: Hace que las capas m√°s profundas sean computacionalmente factibles
- **Regularizaci√≥n**: Ayuda a prevenir el sobreajuste

#### ¬øPor Qu√© Aumentar Filtros (32‚Üí64)?
- **Compensar p√©rdida espacial**: A medida que las dimensiones se reducen, agregar m√°s canales
- **Capturar complejidad**: Las capas m√°s profundas necesitan caracter√≠sticas m√°s abstractas
- **Pr√°ctica est√°ndar**: Com√∫n en arquitecturas CNN

#### ¬øPor Qu√© BatchNormalization?
- **Estabiliza el entrenamiento**: Normaliza las entradas de las capas
- **Convergencia m√°s r√°pida**: Permite tasas de aprendizaje m√°s altas
- **Regularizaci√≥n**: Prevenci√≥n leve del sobreajuste

---

## üî¨ Resultados Experimentales

### Modelo Base vs CNN

| Modelo | Precisi√≥n de Prueba | P√©rdida de Prueba | Par√°metros | Tiempo de Entrenamiento |
|--------|---------------------|-------------------|------------|-------------------------|
| **Base (Dense)** | ~87-88% | ~0.35 | 101,000 | ~30s |
| **CNN (3√ó3)** | ~91-92% | ~0.25 | 94,000 | ~45s |
| **Mejora** | **+4-5%** | **-0.10** | **-7%** | +15s |

**Conclusi√≥n Clave**: CNN logra mejor precisi√≥n con menos par√°metros al explotar la estructura espacial.

---

### Experimento Controlado: Tama√±o de Kernel

**Pregunta de Investigaci√≥n**: ¬øC√≥mo afecta el tama√±o del kernel el rendimiento del modelo?

**Variables de control**: N√∫mero de capas, filtros, pooling, hiperpar√°metros de entrenamiento

| Tama√±o de Kernel | Precisi√≥n de Prueba | Par√°metros | Tiempo de Entrenamiento | Observaciones |
|------------------|---------------------|------------|-------------------------|---------------|
| **3√ó3** | ~91.5% | 94,000 | 45s | ‚úÖ Mejor balance entre precisi√≥n y eficiencia |
| **5√ó5** | ~91.3% | 250,000 | 65s | M√°s par√°metros, precisi√≥n similar |
| **7√ó7** | ~89-90% | 450,000 | 85s | Demasiado agresivo para im√°genes 28√ó28 |

**Conclusi√≥n**: Los kernels 3√ó3 son √≥ptimos para Fashion-MNIST ‚Äì kernels m√°s grandes no mejoran la precisi√≥n pero aumentan la complejidad.

---

### Visualizaciones

El notebook incluye:
- An√°lisis de distribuci√≥n de clases
- Im√°genes de muestra por clase
- Distribuciones de intensidad de p√≠xeles
- Curvas de entrenamiento/validaci√≥n
- Gr√°ficos de comparaci√≥n de tama√±o de kernel
- An√°lisis de compensaciones de rendimiento

---

## üí° Interpretaci√≥n y Conocimientos Clave

### Por Qu√© las CNNs Superan al Modelo Base

1. **Conectividad Local**: Aprovecha la correlaci√≥n entre p√≠xeles cercanos (bordes, texturas)
2. **Compartici√≥n de Par√°metros**: El mismo filtro aplicado en todas partes ‚Üí invariancia por traslaci√≥n
3. **Aprendizaje Jer√°rquico**: Abstracci√≥n progresiva desde bordes hasta partes hasta objetos
4. **Alineaci√≥n del Sesgo Inductivo**: Las suposiciones de CNN coinciden con la estructura de imagen

### ¬øQu√© Sesgo Inductivo Introduce la Convoluci√≥n?

**Tres sesgos clave:**

1. **Localidad**: Los p√≠xeles cercanos son m√°s relevantes que los p√≠xeles distantes
2. **Equivariancia por Traslaci√≥n**: Los patrones son significativos independientemente de su posici√≥n
3. **Composici√≥n Jer√°rquica**: Los patrones complejos se construyen a partir de patrones m√°s simples

Estos sesgos:
- Reducen el espacio de hip√≥tesis ‚Üí aprendizaje m√°s r√°pido
- Requieren menos datos ‚Üí mejor generalizaci√≥n
- Codifican conocimiento del dominio ‚Üí rendimiento mejorado

### ¬øCu√°ndo NO Ser√≠a Apropiada la Convoluci√≥n?

La convoluci√≥n es **inapropiada** para:

1. **Datos Tabulares/Estructurados**: Sin estructura espacial (edad, ingresos, etc.)
2. **Tareas Sensibles a la Posici√≥n**: La ubicaci√≥n importa (diagn√≥stico en imagen m√©dica)
3. **Dependencias de Largo Alcance**: Patrones alejados en el espacio
4. **Grafos Irregulares**: Redes sociales, mol√©culas (necesita GNNs)
5. **Datos Secuenciales con Orden Variable**: Algunas tareas de NLP (usar Transformers)
6. **Datasets Muy Peque√±os**: Datos insuficientes para aprender filtros

**Conocimiento Clave**: Las elecciones arquitect√≥nicas codifican suposiciones ‚Äì las CNNs tienen √©xito cuando las suposiciones coinciden con la estructura del problema.

---

## üìÅ Estructura del Repositorio

```
Exploring-Convolutional-Layers-Through-Data-and-Experiments/
‚îÇ
‚îú‚îÄ‚îÄ README.md                                    # Documentaci√≥n del proyecto
‚îú‚îÄ‚îÄ requirements.txt                             # Dependencias de Python (PyTorch)
‚îú‚îÄ‚îÄ .gitignore                                   # Reglas de ignorar de Git
‚îú‚îÄ‚îÄ convolutional_layers_workshop.ipynb          # Notebook completo del taller ‚≠ê
‚îÇ
‚îî‚îÄ‚îÄ fashion_mnist_cnn_model_pytorch/             # Artefactos del modelo entrenado (generados)
    ‚îú‚îÄ‚îÄ best_model.pth                           # State dict del modelo
    ‚îî‚îÄ‚îÄ complete_model.pth                       # Modelo completo
```

---

## üõ†Ô∏è Configuraci√≥n y Requisitos

### Prerrequisitos

- Python 3.9+ (¬°Compatible con Python 3.14!)
- PyTorch 2.0+
- Jupyter Notebook o JupyterLab

### Instalaci√≥n

1. **Clonar el repositorio**:
   ```bash
   git clone https://github.com/tuusuario/Exploring-Convolutional-Layers-Through-Data-and-Experiments.git
   cd Exploring-Convolutional-Layers-Through-Data-and-Experiments
   ```

2. **Crear entorno virtual** (recomendado):
   ```bash
   python -m venv venv
   source venv/bin/activate  # En Windows: venv\Scripts\activate
   ```

3. **Instalar dependencias**:
   ```bash
   pip install torch torchvision numpy matplotlib seaborn pandas jupyter
   ```

   O usar requirements.txt:
   ```bash
   pip install -r requirements.txt
   ```

### Requirements.txt

```
torch>=2.0.0
torchvision>=0.15.0
numpy>=1.23.0
matplotlib>=3.5.0
seaborn>=0.12.0
pandas>=1.5.0
jupyter>=1.0.0
onnx>=1.14.0  # Para exportaci√≥n de modelos
```

---

## üöÄ C√≥mo Ejecutar

### Opci√≥n 1: Jupyter Notebook

1. Iniciar Jupyter:
   ```bash
   jupyter notebook
   ```

2. Abrir `convolutional_layers_workshop.ipynb`

3. Ejecutar todas las celdas secuencialmente (Cell ‚Üí Run All)

### Opci√≥n 2: JupyterLab

1. Iniciar JupyterLab:
   ```bash
   jupyter lab
   ```

2. Abrir `convolutional_layers_workshop.ipynb`

3. Ejecutar celdas en orden

### Tiempo de Ejecuci√≥n Esperado

- **Ejecuci√≥n completa del notebook**: ~15-20 minutos (CPU)
- **Con GPU**: ~5-8 minutos

### Salida

El notebook:
- Descargar√° Fashion-MNIST autom√°ticamente (solo en la primera ejecuci√≥n)
- Generar√° visualizaciones en l√≠nea
- Mostrar√° el progreso de entrenamiento y m√©tricas
- Guardar√° el modelo entrenado en `fashion_mnist_cnn_model_pytorch/`
- Usar√° GPU autom√°ticamente si est√° disponible (CUDA)

---

## üöÄ Despliegue del Modelo

### Opciones de Despliegue

El modelo PyTorch puede ser desplegado usando varios m√©todos:

#### **1. TorchServe (Recomendado)**
- Framework oficial de PyTorch para servir modelos
- APIs REST y gRPC
- F√°cil escalado y gesti√≥n

#### **2. ONNX Runtime**
- Convertir modelo a formato ONNX para despliegue multiplataforma
- Rendimiento de inferencia optimizado
- Funciona entre frameworks

#### **3. Flask/FastAPI**
- Envoltura simple de API web
- Bueno para despliegue a peque√±a escala
- F√°cil de personalizar

#### **4. Servicios en la Nube**
- AWS Sagemaker (contenedor PyTorch)
- Google Cloud AI Platform
- Azure Machine Learning

### Ejemplo: Exportar a ONNX

```python
import torch

# Cargar modelo
model = torch.load('fashion_mnist_cnn_model_pytorch/complete_model.pth')
model.eval()

# Exportar a ONNX
dummy_input = torch.randn(1, 1, 28, 28)
torch.onnx.export(model, dummy_input, "fashion_mnist_cnn.onnx",
                  input_names=['input'], output_names=['output'])
```

---

## üìö Referencias

### Dataset
- **Fashion-MNIST**: 
  - Xiao, H., Rasul, K., & Vollgraf, R. (2017). Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms. arXiv:1708.07747.
  - GitHub: https://github.com/zalandoresearch/fashion-mnist

### Frameworks
- **PyTorch**: https://pytorch.org/
- **TorchVision**: https://pytorch.org/vision/
- **ONNX**: https://onnx.ai/

### Conceptos Arquitect√≥nicos
- Redes Neuronales Convolucionales (CNNs)
- Sesgo Inductivo en Aprendizaje Profundo
- Aprendizaje de Caracter√≠sticas Jer√°rquicas
- Invariancia por Traslaci√≥n

---

## üéì Resultados de Aprendizaje

Al completar este taller, podr√°s:

‚úÖ Entender por qu√© las CNNs funcionan mejor que las redes totalmente conectadas para im√°genes  
‚úÖ Dise√±ar arquitecturas CNN con justificaciones expl√≠citas  
‚úÖ Conducir experimentos controlados para aislar efectos arquitect√≥nicos  
‚úÖ Interpretar resultados a trav√©s del lente del sesgo inductivo  
‚úÖ Reconocer cu√°ndo NO usar convoluci√≥n  
‚úÖ Desplegar modelos en infraestructura de nube de producci√≥n  

---

## üìù Entregables de la Asignaci√≥n

Este repositorio cumple con todos los requisitos de la asignaci√≥n:

- [x] **Exploraci√≥n del Dataset (EDA)** - Secci√≥n 2
- [x] **Modelo Base** - Secci√≥n 3
- [x] **Dise√±o de Arquitectura CNN** - Secci√≥n 4
- [x] **Experimentos Controlados** - Secci√≥n 5
- [x] **Interpretaci√≥n** - Secci√≥n 6
- [x] **Despliegue del Modelo** - Secci√≥n 7
- [x] **Notebook limpio y ejecutable** - Notebook completo del taller
- [x] **README.md** - Este archivo

---

## üèÜ Conclusiones Clave

1. **Las redes neuronales no son cajas negras** ‚Äì las elecciones arquitect√≥nicas importan
2. **El sesgo inductivo es una caracter√≠stica, no un error** ‚Äì codifica conocimiento del dominio
3. **La experimentaci√≥n supera la intuici√≥n** ‚Äì prueba las suposiciones sistem√°ticamente
4. **La simplicidad a menudo gana** ‚Äì los kernels 3√ó3 superan alternativas m√°s grandes
5. **Comprensi√≥n > Precisi√≥n** ‚Äì saber POR QU√â funciona tu modelo

---

## üìß Contacto

Para preguntas o discusiones sobre este proyecto:
- Abre un issue en este repositorio
- Contacto: [Tu email/informaci√≥n de contacto]

---

**Licencia**: Licencia MIT - si√©ntete libre de usar esto con fines educativos.

**Agradecimientos**: Este proyecto se complet√≥ como parte de una asignaci√≥n de curso de Redes Neuronales enfocada en comprender principios arquitect√≥nicos en lugar de lograr rendimiento de vanguardia.

---

*"El gran aprendizaje autom√°tico no se trata de seguir recetas ‚Äì se trata de entender las suposiciones codificadas en tu arquitectura y si se alinean con la estructura de tu problema."*